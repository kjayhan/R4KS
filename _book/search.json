[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Korean Studies: A Gentle Introduction to Computational Social Science",
    "section": "",
    "text": "Preface\nKorean Studies is traditionally dominated by scholars of history and literature. It’s relatively rare to see R, Python, or other computational social science tools being used or taught in this field.\nI believe computational social science offers huge opportunities for Korean Studies, not only for quantitative research but also for qualitative studies, including those on history and literature!\nIn this book, I aim to increase data literacy and convince as many Korean Studies scholars and students as possible about the relative ease of learning R with code samples, and motivational case studies about Korea.\nI also encourage you to join our bootcamps for problem solving! You can sign up for my newsletter to get updates on the bootcamps.\nCurrent Status of the Book\n\n\n0. Preface: Nearly Complete\n1. Introduction: Nearly Complete\n2. Setting Up: Nearly Complete\n4. The Basics of R: Nearly Complete\n5.. Data Wrangling: Nearly Complete\n9. Text Analysis: 50% Complete\n14. Making Korean Data Visualization Social: Nearly Complete\n15. Bootcamp: Nearly Complete\n\n\nStay Tuned for Updates\nSubscribe to my newsletter to get updates on the book and the bootcamps.\nHow to Cite This Book\nThis book is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License. You can check the license here.\nYou can freely use this book, but you must cite my work to avoid plagiarism. You can cite it in the following way: (Ayhan 2024).\n\n@book{ayhan_2024_r4ks,\n  title = {R for {Korean Studies}: A Gentle Introduction to {Computational Social Science}},\n  author = {Ayhan, Kadir Jun},\n  year = {2024},\n  month = {October},\n  edition = {Draft Version 0.0.2},\n  url = {https://r4ks.com}\n}\n\n\n\n\n\nAyhan, Kadir Jun. 2024. R for Korean Studies: A Gentle Introduction to Computational Social Science. Draft Version 0.0.1. https://r4ks.com.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 “Why Do I Need Computational Tools in Korean Studies?”\nSimply put, there is so much more data out there that is useful for Korean Studies research, and we have faster computers, and handy tools to analyze such data.\nKorean Studies curricula across the world are quite rich and interdisciplinary. Those courses often equip students with the history, culture, literature, and language of Korea to understand the country better. Yet, Korean Studies scholars and students are not exposed to computational methods/ tools that can handle big or complex data as much.\nIf you are already here, it probably means that you appreciate the increasing importance of the computational tools in your research. This book, and bootcamps based on this book, will teach you the basics of R, and give you sample codes based on Korean Studies-related examples.\nIn the age that we live in, I strongly believe that these computational methods/ tools will empower you in your research as well as in the job market given wide range of prospective jobs Korean Studies graduates seek and find (corporations, international organizations, think tanks, NGOs, media, academia etc.).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#why-r",
    "href": "intro.html#why-r",
    "title": "1  Introduction",
    "section": "1.2 “Why R?”",
    "text": "1.2 “Why R?”\nR is free! There are so many packages that are rich with a wide range of functions that you would need in all kinds of research, analysis, and reporting. Many more are being built as you read this book! You can do from simple math to data pre-processing, from data visualization to regressions, from building your CV to building your website, from analyzing tweets to machine learning.\nPython is probably getting more popular in the industry jobs in recent years. Yet, I think, for the time being, R is better suited for social science research. At least there are more books, tutorials, examples that you can learn from in terms of social sciences.\nOnce exposed to R, you may also consider learning Python as well if it seems more attractive for you.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#i-dont-know-anything-about-coding-indeed-i-am-frustrated-about-coding",
    "href": "intro.html#i-dont-know-anything-about-coding-indeed-i-am-frustrated-about-coding",
    "title": "1  Introduction",
    "section": "1.3 “I don’t know anything about coding! Indeed, I am frustrated about coding!”",
    "text": "1.3 “I don’t know anything about coding! Indeed, I am frustrated about coding!”\nThen this book, and the bootcamps, are very much for you! I don’t expect the readers, and bootcamp participants, to have any prior knowledge of R, coding, or other statistical software.\nThis book is supposed to be a gentle introduction, so I do not go into the details of the R language. You can refer to the links that I provide in this book for more information. Furthermore, I also strongly encourage you to use Github's Copilot which is free for academic use, ChatGPT which is not necessarily a coding bot, but still helpful especially for simple tasks, Stackoverflow, and Google for help whenever you are stuck or come across an error.\nLearning curve is steep in the beginning. So you may need a trigger to begin and NOT GIVE UP. This book plays this trigger role. So, there is no need to be intimidated by R, or your lack of background with coding. I got you covered!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "2  Setting Up",
    "section": "",
    "text": "2.1 Installing R\nYou need to install R on your computer. You can download the latest version of R from the CRAN website by clicking one of the mirror links in a location that is close to you. In the next page, you can download the installer for your operating system (Windows, Mac, or Linux).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setting Up</span>"
    ]
  },
  {
    "objectID": "setup.html#installing-rstudio",
    "href": "setup.html#installing-rstudio",
    "title": "2  Setting Up",
    "section": "2.2 Installing RStudio",
    "text": "2.2 Installing RStudio\nAfter installing R, you can download RStudio from the RStudio website. You can download the free version of RStudio Desktop by clicking 2: Install RStudio on the right. It automatically recognizes your operating system and downloads the correct installer for you.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setting Up</span>"
    ]
  },
  {
    "objectID": "setup.html#running-r-on-rstudio",
    "href": "setup.html#running-r-on-rstudio",
    "title": "2  Setting Up",
    "section": "2.3 Running R on RStudio",
    "text": "2.3 Running R on RStudio\nAfter installing R and RStudio, you can open RStudio and start using R.\nWhen you open RStudio, you will see something like in the Figure 2.1.\n\n\n\n\n\n\nFigure 2.1: RStudio\n\n\n\nWell, what you will see will be a default white screen, but you can customize it to look like the one in the image. You can change the theme of RStudio by going to Tools &gt; Global Options &gt; Appearance and selecting the theme you like.\nFor now, pay attention to the two panes in RStudio:\n\nConsole: This is where you can write your R code. For example try writing 1+1 and clicking enter there. You will see the result in the console.\nEnvironment: This is where you can see the objects you have created in your R session. For example, if you write x &lt;- 5 (that is assigning the number ‘5’ to an object named ‘x’) in the source pane, you will see x in the environment pane.\n\nCheck out the The Basics of R chapter to learn the basics of R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setting Up</span>"
    ]
  },
  {
    "objectID": "setup.html#further-information",
    "href": "setup.html#further-information",
    "title": "2  Setting Up",
    "section": "2.4 Further Information",
    "text": "2.4 Further Information\nYou can refer to the following video for further help on installing R and RStudio, unless above information is enough.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setting Up</span>"
    ]
  },
  {
    "objectID": "sources.html",
    "href": "sources.html",
    "title": "3  Korean Studies Data Sources",
    "section": "",
    "text": "3.1 Statistical Data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Korean Studies Data Sources</span>"
    ]
  },
  {
    "objectID": "sources.html#text-data",
    "href": "sources.html#text-data",
    "title": "3  Korean Studies Data Sources",
    "section": "3.2 Text Data",
    "text": "3.2 Text Data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Korean Studies Data Sources</span>"
    ]
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "\n4  The Basics of R\n",
    "section": "",
    "text": "4.1 Creating a Project\nFor each of your new projects, you should create a new project in RStudio. To do this, click on the “File” menu, then “New Project”. You will be asked to choose a directory for your project. Choose a directory where you want to store your project files. You can also create a new directory for your project. After you have chosen a directory, click on “Create Project”. You will see a new RStudio window with your project. You can now start working on your project.\nFor now, this is all you need to know about creating a project. We learn more about projects that are connected with Github in the Productivity Tools chapter.\nWhen you work within a project, managing the files for your project becomes easier. When you work within the project, you don’t need to worry about getting and setting your working directory. To give you an idea, this is how you can find the working directory for your project:\ngetwd()\n\n[1] \"/Users/pd/Library/CloudStorage/OneDrive-Personal/R/projects/R4KS\"\nYou can also set the working directory to some other path using the setwd() function. But you don’t need to do this when you work within a project. On another note, when you are writing code script in an R script file or within a code chunk, you can add non-code comments like this by adding a # sign at the beginning of the line.\n# You can uncomment a comment line and make it a code line by removing the '#' sign at the beginning of the line.\n\n# Replace \"path/to/your/directory\" with the actual path to your directory (folder) that you want to work in.\n\n# Try removing the '#' sign at the beginning of the line and running the code.\n\n# setwd(\"path/to/your/directory\")\nWhen you work within a project, you don’t need to worry about the working directory. You can store all the files for your project in the project directory. You can also save your R scripts in the project directory. This way, you can easily find the files for your project.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#scripting-in-r",
    "href": "basics.html#scripting-in-r",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.2 Scripting in R",
    "text": "4.2 Scripting in R\nYou can simply type your R code in the console and press Enter to run the code. But this is not a good practice. You should write your code in a script file and then run the script file. This way, you can save your code and run it again whenever you want. You can also share your code with others.\nOne of the most important advantages of R, for example over Excel, is that you can reproduce your results. That’s why you should write your code in a script file. Every time you exit R, you should save your R script(s) and then rely on them next time you work on the same project.\n\n4.2.1 Creating a New R Script\nThe most basic way to create a new R script is to click on the “File” menu, then “New File”, and then “R Script”. You will see a new R script file in the RStudio editor. You can now write your R code in this file.\n\n4.2.2 Creating a Quarto File\nYou can also create a new Quarto file by clicking on the “File” menu, then “New File”, and then “Quarto File”. You will see a new Quarto file in the RStudio editor. You can now write your R code in this file.\nQuarto allows you to write your code in chunks. In between chunks, you can have other text, images, and other content. You can also run the code in each chunk and see the output in the document. This is a great way to write reports, papers, and books.\nPersonally I prefer to write my code in Quarto files. When you click to create a new Quarto file, it will ask you to add a title and author, and select a format for your Quarto file. I explain Quarto further in the Storytelling with Quarto chapter. For now, click “Create Empty Document” on the left bottom. Click File &gt; Save and save you Quarto document in your project directory.\nOn the top right of the RStudio editor, you can see a green C button with a + sign. That button allows you to insert a code chunk in your document. See Figure 4.1.\n\n\n\n\n\nFigure 4.1: Quarto: Inserting a New Code Chunk\n\n\nThen after you write your code and when you want to run the code in a chunk, you can click on the green Run button on the right side of the chunk. See Figure 4.2.\n\n\n\n\n\nFigure 4.2: Quarto: Running a Code Chunk\n\n\nWhen you are working in a simple R script, you don’t need to worry about chunks. You can simply write your code in the script file and select the lines of code you want to run and click on the Run button.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#installing-packages",
    "href": "basics.html#installing-packages",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.3 Installing Packages",
    "text": "4.3 Installing Packages\nPackages in R are like apps for your phone. Just like your phone comes with some basic apps, R comes with 14 base packages (as of May 11, 2024) including base, utils, and stats. But you can, and you will need to, install other packages to do different things just like you install apps on your phone.\nYou can install a package using the install.packages() function. This book uses the tidyverse package, which is a universe of packages that follow a common “tidy” data philosophy.\nYou can install the tidyverse package using the following command:\n\n# uncomment the following line by removing \"#\" and run the code to install the tidyverse package\n\n# install.packages(\"tidyverse\")\n\nYou need to install the packages you need only once, and then you can use them whenever you want.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#loading-packages",
    "href": "basics.html#loading-packages",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.4 Loading Packages",
    "text": "4.4 Loading Packages\nJust like apps on your phone, you need to load the packages you need every time you start a new R session. You can load the package using the library() function. For example, to load the tidyverse package, you can use the following command:\n\nlibrary(tidyverse)\n\nThe [tidyverse](https://tidyverse.org/) package is a collection of packages including ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, forcats, rvest, lubridate, and a few other packages. We learn some of these packages in this book. Once you load the tidyverse package, you can use all the functions in these packages. In other words, you don’t need to load, for example, the ggplot2 package separately by running library(ggplot2).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#assigning-values-to-variables",
    "href": "basics.html#assigning-values-to-variables",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.5 Assigning Values to Variables",
    "text": "4.5 Assigning Values to Variables\nYou can assign values to variables in R using the &lt;- operator. For example, you can assign the value 14 to a variable x using the following command:\n\nx &lt;- 14\n\nAfter assigning 14 to x, you can use x in your code. For example, you can print the value of x using the following command:\n\nprint(x)\n\n[1] 14\n\n\nSee, x is now 14. You can also see the value of x by typing x in the console and pressing Enter. Try it.\n\nx\n\n[1] 14\n\n\nYou can also make additional data manipulations using x and assign it to another variable y using the following command:\n\ny &lt;- x + 3\n\nLet’s see the value of y:\n\ny\n\n[1] 17\n\n\nR is an advanced calculator. You can do all kinds of calculations using R. For example, check out the following calculations:\n\n# Square root of 16\nsqrt(16)\n\n[1] 4\n\n# 2 to the power of 8\n2^8\n\n[1] 256\n\n# Logarithm of 100\nlog(100)\n\n[1] 4.60517\n\n# Exponential of previously assigned value y, i.e. 17, times x, i.e. 14.\nexp(y) * x\n\n[1] 338169339\n\n\nYou can also assign a character string to a variable. For example, you can assign the string “한국학 학자들 및 학생들도 R 좀 배웠으면 좋겠다.” to a variable z using the following command:\n\nz &lt;- \"한국학 학자 및 학생들도 R 좀 배웠으면 좋겠다.\"\n\nYou can print the value of z using the following command:\n\nz\n\n[1] \"한국학 학자 및 학생들도 R 좀 배웠으면 좋겠다.\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#make-sure-to-get-the-spelling-right",
    "href": "basics.html#make-sure-to-get-the-spelling-right",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.6 Make sure to get the spelling right!",
    "text": "4.6 Make sure to get the spelling right!\nAs a novice R user, more often than not, you will get error messages because you make mistakes in spelling. For example, we assigned the value 14 to a variable x. If you try to print the value of X instead of x, you will get an error message. Try it.\n\n# Uncomment the following line by removing \"#\" and run the code to see the error message.\n\n# X\n\nYou will get an error message saying that “Error: object ‘X’ not found”. This is because R is case-sensitive. X is not the same as x. Make sure to get the spelling right.\nIf you want to use more than two words for a variable name, you can use an underscore _ (my_variable) or a dot . (my.variable) to separate the words; or you can write the words together with each new word beginning with a capital letter (myVariable). You better be consistent with your naming convention, although technically you can name your variables however you want. For example, you can assign c(\"한국\", \"일본\", \"미국\", \"중국\") to a variable my_variable using the following command:\n\nmy_variable &lt;- c(\"한국\", \"일본\", \"미국\", \"중국\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#data-types",
    "href": "basics.html#data-types",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.7 Data Types",
    "text": "4.7 Data Types\nR has several data types including numeric, character, logical, date, list, dataframe and so on. Let’s see the data types of the variables we created above. We can use the class() function to see the data type of a variable. For example, you can see the data type of x, y, and z using the following commands:\n\nclass(x)\n\n[1] \"numeric\"\n\nclass(y)\n\n[1] \"numeric\"\n\nclass(z)\n\n[1] \"character\"\n\n\nThe data type of x and y is numeric, and the data type of z is character.\nIf we write numbers in quotes, they become character strings. For example, you can assign the string “14” to a variable w using the following command:\n\nw &lt;- \"14\"\n\nYou can see the data type of w using the following command:\n\nclass(w)\n\n[1] \"character\"\n\n\nThe data type of w is character. You can also turn it into a numeric value using the as.numeric() function. For example, you can turn w into a numeric value using the following command:\n\nw &lt;- as.numeric(w)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#vectors",
    "href": "basics.html#vectors",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.8 Vectors",
    "text": "4.8 Vectors\nA vector is a collection of elements of the same data type. You can create a vector using the c() function. For example, you can create a vector v with the elements “서울”, “부산”, “대구”, “인천”, and “대전” using the following command:\n\nv &lt;- c(\"서울\", \"부산\", \"대구\", \"인천\", \"대전\")\n\nYou can print the vector v using the following command:\n\nv\n\n[1] \"서울\" \"부산\" \"대구\" \"인천\" \"대전\"\n\n\nYou can see the data type of v using the following command:\n\nclass(v)\n\n[1] \"character\"\n\n\nThe data type of v is character. You can also create a numeric vector. For example, you can create a vector numbers with the elements 1, -2, 3.1, 49, and 0 using the following command:\n\nnumbers &lt;- c(1, -2, 314, -49, 0)\n\nYou can print the vector numbers using the following command:\n\nnumbers\n\n[1]   1  -2 314 -49   0\n\n\nYou can see the data type of numbers using the following command:\n\nclass(numbers)\n\n[1] \"numeric\"\n\n\nThe data type of numbers is numeric.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#dataframes",
    "href": "basics.html#dataframes",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.9 Dataframes",
    "text": "4.9 Dataframes\nA dataframe is a collection of vectors of the same length. You can create a dataframe using the data.frame() function. For example, you can create a dataframe df with three columns city_name_en, city_name_kr, and population using the following command:\n\n# Relying on this link for the population data (in millions):\n# https://kosis.kr/statHtml/statHtml.do?orgId=101&tblId=DT_1B040A3\n\ndf &lt;- data.frame(city_name_en = c(\"Busan\", \"Daegu\", \"Incheon\", \"Seoul\", \"Daejeon\"),\n                 city_name_kr = c(\"부산\", \"대구\", \"인천\", \"서울\", \"대전\"),\n                 population = c(3.3, 2.4, 3, 9.4, 1.4))\n\nYou can print the dataframe df using the following command:\n\ndf\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n4        Seoul         서울        9.4\n5      Daejeon         대전        1.4\n\n\nYou can see the data type of df using the following command:\n\nclass(df)\n\n[1] \"data.frame\"\n\n\nThe data type of df is dataframe. We can reach the columns of the dataframe using the $ sign. For example, you can see the column city_name_en using the following command:\n\ndf$city_name_en\n\n[1] \"Busan\"   \"Daegu\"   \"Incheon\" \"Seoul\"   \"Daejeon\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#some-basic-functions",
    "href": "basics.html#some-basic-functions",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.10 Some Basic Functions",
    "text": "4.10 Some Basic Functions\nYou can use the head() function to see the first few rows of a dataframe. For example, you can see the first few rows of the dataframe df using the following command:\n\nhead(df)\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n4        Seoul         서울        9.4\n5      Daejeon         대전        1.4\n\n\nBy default, the head() function shows the first 6 rows of the dataframe. You can also specify the number of rows you want to see. For example, you can see the first 3 rows of the dataframe df using the following command:\n\nhead(df, 3)\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n\n\nYou can use the tail() function to see the last few rows of a dataframe. For example, you can see the last few rows of the dataframe df using the following command:\n\ntail(df)\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n4        Seoul         서울        9.4\n5      Daejeon         대전        1.4\n\n\nIn this example, both the head() and tail() functions show the entire dataframe because the dataframe df has only 5 rows. But, in longer dataframes, you can see the first or last few rows using these functions.\nIn a similar vein, glimpse() function from the dplyr package is a function to see the structure of a dataframe. For example, you can see the structure of the dataframe df using the following command:\n\nglimpse(df)\n\nRows: 5\nColumns: 3\n$ city_name_en &lt;chr&gt; \"Busan\", \"Daegu\", \"Incheon\", \"Seoul\", \"Daejeon\"\n$ city_name_kr &lt;chr&gt; \"부산\", \"대구\", \"인천\", \"서울\", \"대전\"\n$ population   &lt;dbl&gt; 3.3, 2.4, 3.0, 9.4, 1.4\n\n\nThe nrow() function gives the number of rows in a dataframe. For example, you can see the number of rows in the dataframe df using the following command:\n\nnrow(df)\n\n[1] 5\n\n\nLikewise, the ncol() function gives the number of columns in a dataframe. For example, you can see the number of columns in the dataframe df using the following command:\n\nncol(df)\n\n[1] 3\n\n\nThe dim() function gives the dimensions of a dataframe. For example, you can see the dimensions of the dataframe df using the following command:\n\ndim(df)\n\n[1] 5 3\n\n\nThe summary() function gives a summary of a dataframe. For example, you can see the summary of the dataframe df using the following command:\n\nsummary(df)\n\n city_name_en       city_name_kr         population \n Length:5           Length:5           Min.   :1.4  \n Class :character   Class :character   1st Qu.:2.4  \n Mode  :character   Mode  :character   Median :3.0  \n                                       Mean   :3.9  \n                                       3rd Qu.:3.3  \n                                       Max.   :9.4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#rows-and-columns",
    "href": "basics.html#rows-and-columns",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.11 Rows and Columns",
    "text": "4.11 Rows and Columns\nYou can select rows and columns of a dataframe using the [] operator. The first argument of the [] operator is the row index, and the second argument is the column index. df[row, column] selects the row with the index row and the column with the index column.\nFor example, you can select the first row and the second column of the dataframe df using the following command:\n\ndf[1, 2]\n\n[1] \"부산\"\n\n\nYou can select the first row of the dataframe df using the following command:\n\ndf[1, ]\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n\n\nYou can select the second column of the dataframe df using the following command:\n\ndf[, 2]\n\n[1] \"부산\" \"대구\" \"인천\" \"서울\" \"대전\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#piping",
    "href": "basics.html#piping",
    "title": "\n4  The Basics of R\n",
    "section": "\n4.12 Piping",
    "text": "4.12 Piping\nThe pipe operators |&gt; and %&gt;% are powerful tools in R.1 The pipe allows you to write code in a more readable way. You can use the pipe operator to pass the output of one function to the input of another function. For example, you can use the pipe operator to pass the dataframe df to the head() function. You can see the first few rows of the dataframe df using the following command:\n\ndf |&gt; head()\n\n  city_name_en city_name_kr population\n1        Busan         부산        3.3\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n4        Seoul         서울        9.4\n5      Daejeon         대전        1.4\n\n\nWe can arrange the dataframe df using the arrange() function from the dplyr package. For example, you can arrange the dataframe df by the population column using the following command with a pipe:\n\ndf |&gt; arrange(population)\n\n  city_name_en city_name_kr population\n1      Daejeon         대전        1.4\n2        Daegu         대구        2.4\n3      Incheon         인천        3.0\n4        Busan         부산        3.3\n5        Seoul         서울        9.4\n\n\narrange() function arranges the dataframe by the selected numeric column in ascending order by default. If it is a character column, it arranges the dataframe in alphabetical order. You can arrange the dataframe in descending order by using the desc() function. For example, you can arrange the dataframe df by the population column in descending order using the following command:\n\ndf |&gt; arrange(desc(population))\n\n  city_name_en city_name_kr population\n1        Seoul         서울        9.4\n2        Busan         부산        3.3\n3      Incheon         인천        3.0\n4        Daegu         대구        2.4\n5      Daejeon         대전        1.4\n\n\nWe can also assign df to the rearranged dataframe. For example, you can assign the arranged dataframe to df using the following command:\n\ndf &lt;- df |&gt; arrange(desc(population))\n\nNow, df is arranged by the population column in descending order. Let’s check out:\n\ndf\n\n  city_name_en city_name_kr population\n1        Seoul         서울        9.4\n2        Busan         부산        3.3\n3      Incheon         인천        3.0\n4        Daegu         대구        2.4\n5      Daejeon         대전        1.4\n\n\nGood. We learned the basics of R. In the next chapter, we learn about data wrangling using mainly the dplyr package.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "basics.html#footnotes",
    "href": "basics.html#footnotes",
    "title": "\n4  The Basics of R\n",
    "section": "",
    "text": "In most cases, these two pipes work the same way. Refer to this link for more explanation on the difference between the base pipe |&gt; and the magrittr pipe %&gt;%. For now, you can simply ignore the difference.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Basics of R</span>"
    ]
  },
  {
    "objectID": "wrangling.html",
    "href": "wrangling.html",
    "title": "\n5  Data Wrangling\n",
    "section": "",
    "text": "5.1 Selecting columns\nWe do not need all the columns in the data. We can select the columns we need using the select() function. For now, I will select only five columns: iso3c (country code), country (country name), year (year), export_kosis (Korea’s exports as reported by Korean Statistical Information Service (KOSIS)), and import_kosis (Korea’s exports as reported by KOSIS).\nWe can either assign the updated object with the selected columns to the same object or a new object. Here, I will assign the updated object to a new object.\ntrade &lt;- trade_data |&gt;\n  select(iso3c, country, year, export_kosis, import_kosis)\nLet’s see how many rows and columns trade_data and trade have.\nnrow(trade_data) # number of rows in trade_data\n\n[1] 16511\nncol(trade_data) # number of columns in trade_data\n\n[1] 18\nnrow(trade) # number of rows in trade\n\n[1] 16511\nncol(trade) # number of columns in trade\n\n[1] 5\ntrade_data has 16511 rows and 18 columns. trade has 16511 rows and 5 columns.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#filtering-rows",
    "href": "wrangling.html#filtering-rows",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.2 Filtering rows",
    "text": "5.2 Filtering rows\nWe can filter rows based on a condition using the filter() function. Here, I will filter rows where the year is larger than 1964. Indeed, KOSIS data starts from 1965. This time, I will assign the updated object to the same object. We need a condition for filtering. In this case, the condition is year &gt; 1964. It is the same as year &gt;= 1965.\n\ntrade &lt;- trade |&gt;\n  filter(year &gt; 1964)\n\nLet’s create a new object with the data from only 2019. == is the condition for equality. We need to use == instead of = for equality condition, and we need to be careful about it.\n\ntrade_2019 &lt;- trade |&gt;\n  filter(year == 2019)\n\n# let's see what the data looks like:\nhead(trade_2019)\n\n# A tibble: 6 × 5\n  iso3c country        year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ABW   Aruba          2019     10396000         1000\n2 AFG   Afghanistan    2019     49930000        38000\n3 AGO   Angola         2019    236830000     16733000\n4 AIA   Anguilla       2019       817000         1000\n5 ALA   Åland Islands  2019           NA            0\n6 ALB   Albania        2019     20744000      3357000\n\n\nLet’s create a new object with the data from only three countries: United States, China, and Japan. We need to use %in% as a condition for multiple values that we look for in the dataframe.\n\ntrade_us_china_japan &lt;- trade |&gt;\n  filter(country %in% c(\"United States\", \"China\", \"Japan\"))\n\n# let's see what the data looks like:\nhead(trade_us_china_japan)\n\n# A tibble: 6 × 5\n  iso3c country  year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 CHN   China    1965           NA           NA\n2 CHN   China    1966           NA           NA\n3 CHN   China    1967           NA           NA\n4 CHN   China    1968           NA           NA\n5 CHN   China    1969           NA           NA\n6 CHN   China    1970           NA           NA\n\n\nWe can filter the rows for multiple years using the %in% operator as well. Let’s create a new object with the data from 2015, 2016, 2017, and 2018. : is used to create a sequence of numbers. 2015:2018 creates a sequence of numbers from 2015 to 2018.\n\ntrade_2015_2018 &lt;- trade |&gt;\n  filter(year %in% 2015:2018)\n\nWe can also filter rows based on multiple conditions. Let’s create a new object with the data from 2015, 2016, 2017, and 2018 using the & operator, which means “and”.\n\ntrade_2015_2018_backup &lt;- trade |&gt;\n  filter(year &gt;= 2015 # year is greater than or equal to 2015\n         & # and\n         year &lt;= 2018 # year is less than or equal to 2018\n         )\n\nLet’s check if trade_2015_2018 and trade_2015_2018_backup are the same.\n\nidentical(trade_2015_2018, trade_2015_2018_backup)\n\n[1] TRUE\n\n\nNow, let’s filter the data for 2015, 2016, 2017, and 2018 for the United States, China, and Japan, this time using country codes.\n\ntrade_us_china_japan_2015_2018 &lt;- trade |&gt;\n  filter(year %in% 2015:2018 # included years are 2015, 2016, 2017, and 2018\n         & # and\n         iso3c %in% c(\"USA\", \"CHN\", \"JPN\") # included country codes are USA, CHN, and JPN\n         )\n\n# let's see what the data looks like:\nhead(trade_us_china_japan_2015_2018)\n\n# A tibble: 6 × 5\n  iso3c country  year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 CHN   China    2015 137123934000  90250275000\n2 CHN   China    2016 124432941000  86980135000\n3 CHN   China    2017 142120000000  97860114000\n4 CHN   China    2018 162125055000 106488592000\n5 JPN   Japan    2015  25576507000  45853834000\n6 JPN   Japan    2016  24355036000  47466592000\n\n\nTwo other operators that we can use for filtering are | and !. | means “or” and ! means “not”. Let’s create a new object with the data for 2015, 2016, 2017, and 2018 or the export volume is larger than 100 billion USD.\n\ntrade_2015_2018_or_export &lt;- trade |&gt;\n  filter(year %in% 2015:2018 # included years are 2015, 2016, 2017, and 2018\n         | #or\n         export_kosis &gt; 110000000000 # export volume is larger than 110 billion USD\n         )\n\nLet’s see what else is included that is not in the years 2015, 2016, 2017, and 2018.\n\ntrade_2015_2018_or_export |&gt;\n  filter(!year %in% 2015:2018) #  excluded years are 2015, 2016, 2017, and 2018\n\n# A tibble: 11 × 5\n   iso3c country        year export_kosis import_kosis\n   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 CHN   China          2010 116837833000  71573603000\n 2 CHN   China          2011 134185009000  86432238000\n 3 CHN   China          2012 134322564000  80784595000\n 4 CHN   China          2013 145869498000  83052877000\n 5 CHN   China          2014 145287701000  90082226000\n 6 CHN   China          2019 136202533000 107228736000\n 7 CHN   China          2020 132565445000 108884645000\n 8 CHN   China          2021 162912974000 138628127000\n 9 CHN   China          2022 155789389000 154576314000\n10 CHN   China          2023 124817682000 142857338000\n11 USA   United States  2023 115696334000  71272030000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#arranging-rows",
    "href": "wrangling.html#arranging-rows",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.3 Arranging rows",
    "text": "5.3 Arranging rows\nWe can arrange rows based on a column using the arrange() function. Let’s arrange the data by year in ascending order.\n\ntrade &lt;- trade |&gt;\n  arrange(year)\n\nhead(trade)\n\n# A tibble: 6 × 5\n  iso3c country        year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ABW   Aruba          1965           NA           NA\n2 AFG   Afghanistan    1965           NA           NA\n3 AGO   Angola         1965           NA           NA\n4 AIA   Anguilla       1965           NA           NA\n5 ALA   Åland Islands  1965           NA           NA\n6 ALB   Albania        1965           NA           NA\n\n\nWe can arrange by year in descending order.\n\ntrade &lt;- trade |&gt;\n  arrange(desc(year))\n\nhead(trade)\n\n# A tibble: 6 × 5\n  iso3c country        year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ABW   Aruba          2023     21005000       121000\n2 AFG   Afghanistan    2023     25079000      1045000\n3 AGO   Angola         2023    474761000        11000\n4 AIA   Anguilla       2023        96000        10000\n5 ALA   Åland Islands  2023        15000            0\n6 ALB   Albania        2023    142311000     11053000\n\n\nWe can arrange alphabetically by country codes in ascending order.\n\ntrade &lt;- trade |&gt;\n  arrange(iso3c)\n\nhead(trade)\n\n# A tibble: 6 × 5\n  iso3c country  year export_kosis import_kosis\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 ABW   Aruba    2023     21005000       121000\n2 ABW   Aruba    2022     24954000        15000\n3 ABW   Aruba    2021     11612000     93314000\n4 ABW   Aruba    2020      3070000     83864000\n5 ABW   Aruba    2019     10396000         1000\n6 ABW   Aruba    2018     14807000      2935000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#mutating-columns",
    "href": "wrangling.html#mutating-columns",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.4 Mutating columns",
    "text": "5.4 Mutating columns\nWe can create new columns or update existing columns using the mutate() function. Let’s create a new column, trade_kosis, which is the total trade volume of Korea with a country in a year. The total trade volume is the sum of exports and imports.\n\ntrade &lt;- trade |&gt;\n  mutate(trade_kosis = export_kosis + import_kosis)\n\nhead(trade)\n\n# A tibble: 6 × 6\n  iso3c country  year export_kosis import_kosis trade_kosis\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 ABW   Aruba    2023     21005000       121000    21126000\n2 ABW   Aruba    2022     24954000        15000    24969000\n3 ABW   Aruba    2021     11612000     93314000   104926000\n4 ABW   Aruba    2020      3070000     83864000    86934000\n5 ABW   Aruba    2019     10396000         1000    10397000\n6 ABW   Aruba    2018     14807000      2935000    17742000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#grouping-and-summarizing-data",
    "href": "wrangling.html#grouping-and-summarizing-data",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.5 Grouping and summarizing data",
    "text": "5.5 Grouping and summarizing data\nWe can group data based on one or more columns using the group_by() function. We can summarize data based on the groups using the summarize() function. Let’s group the data by year and summarize the total trade volume of Korea in each year.\nWe need to be careful about one thing. There are missing values in the data. We need to ignore them (in other words treat them as zero) when we calculate the total trade volume. Otherwise, the total trade volume will be NA if there is at least one missing value in the data for a year. We can use the na.rm = TRUE argument in the sum() function to remove missing values.\n\ntrade_volume &lt;- trade |&gt;\n  group_by(year) |&gt;\n  summarize(total_trade_kosis = sum(trade_kosis, na.rm = TRUE)) |&gt;\n  arrange(desc(total_trade_kosis))\n\nhead(trade_volume)\n\n# A tibble: 6 × 2\n   year total_trade_kosis\n  &lt;dbl&gt;             &lt;dbl&gt;\n1  2022     1400216998000\n2  2023     1270073156000\n3  2021     1248778081000\n4  2018     1127928070000\n5  2014     1092728073000\n6  2011     1077938860000\n\n\nWe can also group the data by country. Let’s summarize the total trade volume of Korea with each country since 1965.\n\ntrade_country &lt;- trade |&gt;\n  group_by(country) |&gt;\n  summarize(total_trade_kosis = sum(trade_kosis, na.rm = TRUE)) |&gt;\n  arrange(desc(total_trade_kosis))\n\nhead(trade_country)\n\n# A tibble: 6 × 2\n  country             total_trade_kosis\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 China                   4455699092000\n2 United States           3179689314000\n3 Japan                   2424243884000\n4 Vietnam                  773845848000\n5 Hong Kong SAR China      759431632000\n6 Saudi Arabia             753711941000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#conditional-mutating",
    "href": "wrangling.html#conditional-mutating",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.6 Conditional Mutating",
    "text": "5.6 Conditional Mutating\nWe can conditionally mutate columns using the case_when() function. Let’s create a new column, trade_status, which is “surplus” if the export volume is larger than the import volume, “deficit” if the import volume is larger than the export volume, and “balanced” if the export volume is equal to the import volume. If the export or import volume is missing, we will make the trade status “unknown”. We can use is.na() to check if a value is missing.\n\ntrade &lt;- trade |&gt;\n  mutate(trade_status = case_when(\n    export_kosis &gt; import_kosis ~ \"surplus\", # export volume is larger than import volume\n    export_kosis &lt; import_kosis ~ \"deficit\", # export volume is less than import volume\n    export_kosis == import_kosis ~ \"balanced\", # export volume is equal to import volume\n    is.na(export_kosis) | is.na(import_kosis) ~ \"unknown\", # export or import volume is missing\n    TRUE ~ \"everything else\" # in this instance, we do not need \"TRUE ~\" since we cover all `case_when()` options above. But in other cases, you may need it. \"TRUE ~\" basically helps you assign a new value for every other condition that is not mentioned above.\n  ))\n\nhead(trade)\n\n# A tibble: 6 × 7\n  iso3c country  year export_kosis import_kosis trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;       \n1 ABW   Aruba    2023     21005000       121000    21126000 surplus     \n2 ABW   Aruba    2022     24954000        15000    24969000 surplus     \n3 ABW   Aruba    2021     11612000     93314000   104926000 deficit     \n4 ABW   Aruba    2020      3070000     83864000    86934000 deficit     \n5 ABW   Aruba    2019     10396000         1000    10397000 surplus     \n6 ABW   Aruba    2018     14807000      2935000    17742000 surplus     \n\n\nIn this instance, we do not need “TRUE ~” since we cover all case_when() options above. But in other cases, you may need it. “TRUE ~” basically helps you assign a new value for every other condition that is not mentioned above.\nWe can create a table using the table() function for the trade status of Korea since 1965.\n\ntable(trade$trade_status)\n\n\nbalanced  deficit  surplus  unknown \n     143     3134     6567     5444",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#merging-datasets",
    "href": "wrangling.html#merging-datasets",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.7 Merging datasets",
    "text": "5.7 Merging datasets\nRight now, we only have one dataset. Let’s get another dataset from the WDI package, which includes World Bank’s World Development Indicators data. Let’s install the package if you do not have it yet.\n\n# install.packages(\"WDI\") # if you haven't installed the WDI package yet, remove the # sign.\n\nlibrary(WDI) # load the WDI package\n\nLet’s get the data for the GDP of all countries since 1965. You can search for indicators from the World Bank’s World Development Indicators database here or using the WDIsearch function in the WDI package. For details, you can check out WDI’s documentation using the ? function or its Github page.\n\nwdi &lt;- WDI(country = \"all\", # all countries\n           indicator = c(\"gdp\" = \"NY.GDP.MKTP.KD\", # GDP at constant 2015 US dollars\n                         \"gdp_pc\" = \"NY.GDP.PCAP.KD\"), # GDP per capita at constant 2015 US dollars \n           start = 1965, # start year\n           end = 2024, # end year\n           extra = TRUE, # include extra columns included in the WDI package defaults\n           language = \"en\" # language is English\n           )\n\nhead(wdi)\n\n      country iso2c iso3c year status lastupdated        gdp   gdp_pc\n1 Afghanistan    AF   AFG 1965         2024-09-19         NA       NA\n2 Afghanistan    AF   AFG 2003         2024-09-19 7867263256 347.4152\n3 Afghanistan    AF   AFG 1966         2024-09-19         NA       NA\n4 Afghanistan    AF   AFG 2005         2024-09-19 8874480196 363.5415\n5 Afghanistan    AF   AFG 1971         2024-09-19         NA       NA\n6 Afghanistan    AF   AFG 2002         2024-09-19 7228795919 344.2242\n      region capital longitude latitude     income lending\n1 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n2 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n3 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n4 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n5 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n6 South Asia   Kabul   69.1761  34.5228 Low income     IDA\n\n\nWe wanted extra WDI data, but we don’t need all. Let’s select the ones we need. This time, let’s exclude the columns we do not need by using the - sign. Then let’s exclude non-country groups (e.g., “High income”, “Not classified”) by filtering out rows where the iso3c column is missing. Then let’s arrange the data by country code and year.\n\nwdi &lt;- wdi |&gt;\n  #select(-iso2c, -status, -lastupdated, -capital, -lending, -longitude, -latitude) |&gt; # exclude these columns\n  filter(!is.na(iso3c)) |&gt; # exclude the rows that are missing country codes (in other words, we only include the ones that are not (!) missing country codes (iso3c))\n  arrange(iso3c, year) # arrange the data by country code and year\n\nhead(wdi)\n\n              country iso2c iso3c year status lastupdated          gdp\n1         High income    XD       1965         2024-09-19 1.214382e+13\n2          Low income    XM       1965         2024-09-19           NA\n3 Lower middle income    XN       1965         2024-09-19 5.474380e+11\n4      Not classified    XY       1965         2024-09-19           NA\n5 Upper middle income    XT       1965         2024-09-19 1.481616e+12\n6         High income    XD       1966         2024-09-19 1.281436e+13\n      gdp_pc region capital longitude latitude income lending\n1 12593.9054   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n2         NA   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n3   584.5733   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n4         NA   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n5  1171.4299   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n6 13154.2957   &lt;NA&gt;    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;\n\n\nThis did not work out. Probably these entries are not missing, but instead simply empty! Let’s check that. Let’s try filtering out empty country codes (instead of missing country codes which we checked with is.na()).\n\nwdi &lt;- wdi |&gt;\n  filter(iso3c != \"\") # exclude the rows that have empty country codes. We check it as an empty character. \"!=\" means not equal to.\n\nhead(wdi)\n\n  country iso2c iso3c year status lastupdated gdp gdp_pc\n1   Aruba    AW   ABW 1965         2024-09-19  NA     NA\n2   Aruba    AW   ABW 1966         2024-09-19  NA     NA\n3   Aruba    AW   ABW 1967         2024-09-19  NA     NA\n4   Aruba    AW   ABW 1968         2024-09-19  NA     NA\n5   Aruba    AW   ABW 1969         2024-09-19  NA     NA\n6   Aruba    AW   ABW 1970         2024-09-19  NA     NA\n                     region    capital longitude latitude      income\n1 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n2 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n3 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n4 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n5 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n6 Latin America & Caribbean Oranjestad  -70.0167  12.5167 High income\n         lending\n1 Not classified\n2 Not classified\n3 Not classified\n4 Not classified\n5 Not classified\n6 Not classified\n\n\nYes, that was it. Instead of NA, those country code columns were empty for those rows. Now that we successfully filtered out the rows with empty country codes, let’s join Korea’s trade data with the WDI data. There are different types of joins. I will explain five of them. To make things easier, I will create smaller datasets for the demonstration. We will have only the data for the United States, China, and Japan in the trade data. We will have only the data for the United States, Japan and Italy in the WDI data.\n\ntrade_df &lt;- trade |&gt;\n  filter(iso3c %in% c(\"USA\", \"CHN\", \"JPN\"))\n\nhead(trade_df)\n\n# A tibble: 6 × 7\n  iso3c country  year export_kosis import_kosis  trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 CHN   China    2023 124817682000 142857338000 267675020000 deficit     \n2 CHN   China    2022 155789389000 154576314000 310365703000 surplus     \n3 CHN   China    2021 162912974000 138628127000 301541101000 surplus     \n4 CHN   China    2020 132565445000 108884645000 241450090000 surplus     \n5 CHN   China    2019 136202533000 107228736000 243431269000 surplus     \n6 CHN   China    2018 162125055000 106488592000 268613647000 surplus     \n\n\n\nwdi_df &lt;- wdi |&gt;\n  filter(iso3c %in% c(\"USA\", \"JPN\", \"ITA\"))\n\n\n\nDataframes\n\n\n5.7.1 inner_join\ninner_join returns only the rows that have matching values in both datasets. Let’s join the trade_df and wdi_df datasets using the iso3c and year columns.\n\ninner_df &lt;- inner_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"))\n\n# you can also write it like this:\n\n# inner_df &lt;- trade_df |&gt; inner_join(wdi_df, by = c(\"iso3c\", \"year\"), suffix = c(\"_trade\", \"_wdi\"))\n\n\nhead(inner_df)\n\n# A tibble: 6 × 19\n  iso3c country.x  year export_kosis import_kosis trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;       \n1 JPN   Japan      2023  29000616000  47656468000 76657084000 deficit     \n2 JPN   Japan      2022  30606278000  54711795000 85318073000 deficit     \n3 JPN   Japan      2021  30061806000  54642165000 84703971000 deficit     \n4 JPN   Japan      2020  25097651000  46023036000 71120687000 deficit     \n5 JPN   Japan      2019  28420213000  47580853000 76001066000 deficit     \n6 JPN   Japan      2018  30528580000  54603749000 85132329000 deficit     \n# ℹ 12 more variables: country.y &lt;chr&gt;, iso2c &lt;chr&gt;, status &lt;chr&gt;,\n#   lastupdated &lt;chr&gt;, gdp &lt;dbl&gt;, gdp_pc &lt;dbl&gt;, region &lt;chr&gt;, capital &lt;chr&gt;,\n#   longitude &lt;chr&gt;, latitude &lt;chr&gt;, income &lt;chr&gt;, lending &lt;chr&gt;\n\n\n\n\ninner_join\n\nThe column names that we will join by are the same in both dataframes (“iso3c” and “year”). If it was not the same, we could write the code as follows:\n\ninner_df &lt;- inner_join(trade_df, wdi_df, by = c(\"iso3c\" = \"iso3c\", \"year\" = \"year\")) # the first element is from the first dataframe and the second element is from the second dataframe.\n\nIf, for example, the country code column name was “country_code” and the year column was “Year” in trade_df, you would replace the first “iso3c” with “country_code” and the first “year” with “Year”.\nIf there are columns with the same name in both dataframes other than the columns you use to join them, you can use the suffix argument to add a suffix to the column names. For example, in this case, we have columns named “country” in both dataframes. Since we didn’t have suffix in the above code, we have two columns “country.x” and “country.y”. If you want to add suffices, you can do it as follows:\n\ninner_df &lt;- inner_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"), suffix = c(\"_trade\", \"_wdi\"))\n\nhead(inner_df)\n\n# A tibble: 6 × 19\n  iso3c country_trade  year export_kosis import_kosis trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;       \n1 JPN   Japan          2023  29000616000  47656468000 76657084000 deficit     \n2 JPN   Japan          2022  30606278000  54711795000 85318073000 deficit     \n3 JPN   Japan          2021  30061806000  54642165000 84703971000 deficit     \n4 JPN   Japan          2020  25097651000  46023036000 71120687000 deficit     \n5 JPN   Japan          2019  28420213000  47580853000 76001066000 deficit     \n6 JPN   Japan          2018  30528580000  54603749000 85132329000 deficit     \n# ℹ 12 more variables: country_wdi &lt;chr&gt;, iso2c &lt;chr&gt;, status &lt;chr&gt;,\n#   lastupdated &lt;chr&gt;, gdp &lt;dbl&gt;, gdp_pc &lt;dbl&gt;, region &lt;chr&gt;, capital &lt;chr&gt;,\n#   longitude &lt;chr&gt;, latitude &lt;chr&gt;, income &lt;chr&gt;, lending &lt;chr&gt;\n\n\n\n5.7.2 left_join\nleft_join returns all the rows from the left dataset and the matched rows from the right dataset. If there is no match, the result is NA. Let’s join the trade_df and wdi_df datasets using the iso3c and year columns.\n\n\nleft_join\n\n\nleft_df &lt;- left_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"))\n\nhead(left_df)\n\n# A tibble: 6 × 19\n  iso3c country.x  year export_kosis import_kosis  trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 CHN   China      2023 124817682000 142857338000 267675020000 deficit     \n2 CHN   China      2022 155789389000 154576314000 310365703000 surplus     \n3 CHN   China      2021 162912974000 138628127000 301541101000 surplus     \n4 CHN   China      2020 132565445000 108884645000 241450090000 surplus     \n5 CHN   China      2019 136202533000 107228736000 243431269000 surplus     \n6 CHN   China      2018 162125055000 106488592000 268613647000 surplus     \n# ℹ 12 more variables: country.y &lt;chr&gt;, iso2c &lt;chr&gt;, status &lt;chr&gt;,\n#   lastupdated &lt;chr&gt;, gdp &lt;dbl&gt;, gdp_pc &lt;dbl&gt;, region &lt;chr&gt;, capital &lt;chr&gt;,\n#   longitude &lt;chr&gt;, latitude &lt;chr&gt;, income &lt;chr&gt;, lending &lt;chr&gt;\n\n\n\n5.7.3 right_join\nright_join returns all the rows from the right dataset and the matched rows from the left dataset. If there is no match, the result is NA. Let’s join the trade_df and wdi_df datasets using the iso3c and year columns.\n\n\nright_join\n\n\nright_df &lt;- right_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"), suffix = c(\"_trade\", \"_wdi\"))\n\nhead(right_df)\n\n# A tibble: 6 × 19\n  iso3c country_trade  year export_kosis import_kosis trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;       \n1 JPN   Japan          2023  29000616000  47656468000 76657084000 deficit     \n2 JPN   Japan          2022  30606278000  54711795000 85318073000 deficit     \n3 JPN   Japan          2021  30061806000  54642165000 84703971000 deficit     \n4 JPN   Japan          2020  25097651000  46023036000 71120687000 deficit     \n5 JPN   Japan          2019  28420213000  47580853000 76001066000 deficit     \n6 JPN   Japan          2018  30528580000  54603749000 85132329000 deficit     \n# ℹ 12 more variables: country_wdi &lt;chr&gt;, iso2c &lt;chr&gt;, status &lt;chr&gt;,\n#   lastupdated &lt;chr&gt;, gdp &lt;dbl&gt;, gdp_pc &lt;dbl&gt;, region &lt;chr&gt;, capital &lt;chr&gt;,\n#   longitude &lt;chr&gt;, latitude &lt;chr&gt;, income &lt;chr&gt;, lending &lt;chr&gt;\n\n\n\n5.7.4 full_join\nfull_join returns all the rows from both datasets. If there is no match, the result is NA. Let’s join the trade_df and wdi_df datasets using the iso3c and year columns.\n\n\nfull_join\n\n\nfull_df &lt;- full_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"), suffix = c(\"_trade\", \"_wdi\"))\n\nhead(full_df)\n\n# A tibble: 6 × 19\n  iso3c country_trade  year export_kosis import_kosis  trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 CHN   China          2023 124817682000 142857338000 267675020000 deficit     \n2 CHN   China          2022 155789389000 154576314000 310365703000 surplus     \n3 CHN   China          2021 162912974000 138628127000 301541101000 surplus     \n4 CHN   China          2020 132565445000 108884645000 241450090000 surplus     \n5 CHN   China          2019 136202533000 107228736000 243431269000 surplus     \n6 CHN   China          2018 162125055000 106488592000 268613647000 surplus     \n# ℹ 12 more variables: country_wdi &lt;chr&gt;, iso2c &lt;chr&gt;, status &lt;chr&gt;,\n#   lastupdated &lt;chr&gt;, gdp &lt;dbl&gt;, gdp_pc &lt;dbl&gt;, region &lt;chr&gt;, capital &lt;chr&gt;,\n#   longitude &lt;chr&gt;, latitude &lt;chr&gt;, income &lt;chr&gt;, lending &lt;chr&gt;\n\n\n\n5.7.5 anti_join\nanti_join returns all the rows from the left dataset that do not have a match in the right dataset. Let’s join the trade_df and wdi_df datasets using the iso3c and year columns.\n\n\nanti_join\n\n\nanti_df &lt;- anti_join(trade_df, wdi_df, by = c(\"iso3c\", \"year\"))\n\nhead(anti_df)\n\n# A tibble: 6 × 7\n  iso3c country  year export_kosis import_kosis  trade_kosis trade_status\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;       \n1 CHN   China    2023 124817682000 142857338000 267675020000 deficit     \n2 CHN   China    2022 155789389000 154576314000 310365703000 surplus     \n3 CHN   China    2021 162912974000 138628127000 301541101000 surplus     \n4 CHN   China    2020 132565445000 108884645000 241450090000 surplus     \n5 CHN   China    2019 136202533000 107228736000 243431269000 surplus     \n6 CHN   China    2018 162125055000 106488592000 268613647000 surplus",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#a-note-on-country-codes",
    "href": "wrangling.html#a-note-on-country-codes",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.8 A Note on Country Codes",
    "text": "5.8 A Note on Country Codes\nIt is often easier to work with standard country codes than country names when we work with multiple datasets. There are a few widely used standard country codes. Above, we used the ISO 3166-1 alpha-3 country codes. There are other commonly used country codes such as Correlates of War (COW) country codes, Varieties of Democracy (V-Dem) country codes, and more.\nWe can convert country names to country codes using the countrycode package. Let’s install the package if you do not have it yet.\n\n# install.packages(\"countrycode\") # if you haven't installed the countrycode package yet, remove the # sign.\n\nlibrary(countrycode) # load the countrycode package\n\nLet’s convert the country names in the trade_df dataset to Correlates of War country codes. You can find the countrycode documentantion on its Github page or by using the ? function.\n\n# ?countrycode\n\ntrade_df &lt;- trade_df |&gt;\n  mutate(cown = countrycode(country, origin = \"country.name\", destination = \"cown\")) # convert country names to Correlates of War numeric country codes (cown)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#a-note-on-working-with-korean-country-nameswrangling-1",
    "href": "wrangling.html#a-note-on-working-with-korean-country-nameswrangling-1",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.9 A Note on Working with Korean Country Names1\n",
    "text": "5.9 A Note on Working with Korean Country Names1\n\nIn my research, I often work with country-year data from Korean sources, including data on diplomatic visits, trade, aid and so on. One of the fundamental difficulties I have had is the lack of universal country codes across different datasets. Further complicating matters is the inconsistency of country names in these datasets. For example, Democratic Republic of the Congo has five different spellings across different official sources that I could find: 콩고 민주공화국, 자이르, 콩고민주공화국, 콩고 민주 공화국, 콩고민주공화국(DR콩고).\nTo address this issue, I have created a function in my kdiplo package that converts Korean country names into ISO 3166-1 alpha-3 (iso3c) country codes. This function, iso3c_kr, is designed to assign universal iso3c country codes to Korean-language country names that will make it easier to join different kinds of data.\nOne still needs to check if the output is correct, especially for countries that have gone through political transitions such as Germany, Yugoslavia, Russia, Vietnam, Yemen and so on.\nSometimes the Korean government sources have overlapping data for Yugoslavia and Serbia, for example. In such cases, one needs to check the data and make sure that the data is correct.\nFor example, the following is sample Korean trade data from Korean Statistical Information Service (KOSIS):\n\n# install.packages(\"readxl\") # if you haven't installed the readxl package yet, remove the # sign.\n\nlibrary(readxl) # load the readxl package\n\n# let's read the xlsx data\n\nkosis_trade &lt;- read_xlsx(\"data/kosis_trade_240330.xlsx\")\n\n# let's take a look at the data\n\n# install.packages(\"gt\") # if you haven't installed the gt package yet, remove the # sign.\n\n# let's take a look at some of the data\n\n# remember, [row, column] format can be used in R for subsetting dataframes. So, we can look at rows 533 to 538 and columns 1 and 57 to 62.\n\nkosis_trade[533:538,c(1,57:62)] |&gt; gt::gt() \n\n\n\n\n\n\n국가별\n2018 년\n2019 년\n2020 년\n2021 년\n2022 년\n2023 년\n\n\n\n잠비아\n26241\n16087\n17619\n28356\n14068\n15459\n\n\n잠비아\n108344\n54542\n15164\n100606\n82198\n53867\n\n\n자이르\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n자이르\n618\n8\n113\n4\nNA\nNA\n\n\n짐바브웨\n25964\n14088\n15514\n20404\n16083\n19563\n\n\n짐바브웨\n4909\n13098\n11377\n9627\n10415\n20862\n\n\n\n\n\n\n# you can use the gt package to create a table.\n# you can use \"::\" to access the functions in the package without loading the package.\n\nAnd, the following is sample Korean aid data from Korea’s ODA portal:\n\naid &lt;- read_xlsx(\"data/korea_total_aid_2019_230709.xlsx\")\n\n\naid &lt;- aid |&gt; select(1:5) # we only need the first five columns\n\naid &lt;- aid |&gt; set_names(c(\"country_kr\", \"sector\", \"no_of_projects\", \"aid_usd\", \"aid_krw\"))\n\n# This sample data is only 2019; so we will add the year column, and assign 2019 to all rows.\n\naid$year &lt;- 2019\n\n# let's take a look at some of the data\naid[c(50, 150, 250, 350, 450),] |&gt; gt::gt()\n\n\n\n\n\n\ncountry_kr\nsector\nno_of_projects\naid_usd\naid_krw\nyear\n\n\n\n베트남\n통신정책, 계획 및 행정(voluntary code)\n2\n232334\n270736486\n2019\n\n\n캄보디아\n11321\n1\n85815\n99999361\n2019\n\n\n미얀마\n사회보호/보장\n1\n103460\n120560903\n2019\n\n\n라오스\n비정규 농업훈련\n1\n107958\n125802378\n2019\n\n\n몽골\n의료서비스\n5\n511824\n596423389\n2019\n\n\n\n\n\n\n\n\n5.9.1 Converting wide data to long format\nWide format is quite common in official Korean data sources. Trade data is in wide format. Before using the iso3c_kr function, let’s first transform the trade data into a long (country-year) format to make it in the same format as the aid data. This will make joining the two datasets more feasible.\nTo convert the trade data into a long format, we will use the pivot_longer() function from the tidyr package.\n\n# we will divide the trade data into export and import data\n\nexport &lt;- kosis_trade \n\nimport &lt;- kosis_trade\n\nIn pivot_longer(), we need to specify the columns that we want to pivot. In this case, we want to pivot columns 4 to 62, which are years. We also need to specify the names of the columns that will be created. In this case, we will create a column called year and a column called export_kosis for the export data. We will create a column called year and a column called import_kosis for the import data.\n\nexport_long &lt;- export |&gt; \n  pivot_longer(4:62, names_to = \"year\", values_to = \"export_kosis\") # we will pivot the data from wide to long format\n\nWe can rename the columns using set_names function in rlang package, which is also a member of the tidyverse family, to make them more informative.\n\nexport_long &lt;- export_long |&gt; \n  set_names(c(\"country_kr\", \"type\", \"unit\", \"year\", \"export_kosis\"))\n\nWe can filter the data for only export data using the filter() function. We can also convert the export data from thousands of dollars to dollars by multiplying the export_kosis column by 1000. We can also convert the year column to numeric using the parse_number() function from the readr package, which is also a member of the tidyverse family.\n\nexport_long &lt;- export_long |&gt;\n  filter(type == \"수출액[천달러]\") |&gt; # we only need the export data which has the column name in Korean as \"수출액[천달러]\"\n  mutate(export_kosis = parse_number(export_kosis) * 1000, # we convert the export data from thousands of dollars to dollars; sometimes there are commas that make the data character instead of numeric. So we use parse_number() function from the readr package to convert character to numeric data.\n         year = parse_number(year)) |&gt; # we convert the year column to numeric using parse_number() function from the readr package\n  select(-type, -unit) # we do not need the type and unit columns\n\nWe repeat the same steps for the import data.\n\nimport_long &lt;- import |&gt; \n  pivot_longer(4:62, names_to = \"year\", values_to = \"import_kosis\")\n\nimport_long &lt;- import_long |&gt; \n  set_names(c(\"country_kr\", \"type\", \"unit\", \"year\", \"import_kosis\"))\n\n\nimport_long &lt;- import_long |&gt;\n  filter(type == \"수입액[천달러]\") |&gt; \n  mutate(import_kosis = parse_number(import_kosis) * 1000,\n         year = parse_number(year)) |&gt;\n  select(-type, -unit)\n\nNow, we can join the export and import data using the left_join() function.\n\ntrade_long &lt;- export_long |&gt; \n  left_join(import_long, by = c(\"country_kr\", \"year\"))\n\nHere, we get a warning message that there are rows that have the same country name and year in both the export and import data. It is because, KOSIS reported trade with Palestine in two separate entries (probably, West Bank and Gaza are recorded separately), but assigning both the same name “팔레스타인 해방기구”. We will ignore this warning for now.\n\n5.9.2 iso3c_kr function to convert Korean country names to iso3c country codes\nUsing the iso3c_kr function, we can simply convert Korean country names into iso3c country codes. For example, the following is the output of the iso3c_kr function for the Korean trade data:\n\ntrade_long &lt;- iso3c_kr(trade_long, \"country_kr\") #you copy paste the column name that has the Korean country names.\n\ntrade_long[c(50, 150, 250, 350, 450, 550), c(1,5, 2:4)] |&gt; gt::gt()\n\n\n\n\n\n\ncountry_kr\niso3c\nyear\nexport_kosis\nimport_kosis\n\n\n\n계\nNA\n2014\n572664607000\n525514506000\n\n\n아랍에미리트 연합\nARE\n1996\n1377933000\n2259205000\n\n\n앤티가바부다\nATG\n1978\nNA\nNA\n\n\n앵귈라\nAIA\n2019\n817000\n1000\n\n\n아르메니아\nARM\n2001\n1255000\n43000\n\n\n앙골라\nAGO\n1983\n235000\nNA\n\n\n\n\n\n\n\nWe see that in this example, “계” (gyae) did not get any iso3c country code. This is because the iso3c_kr function could not find the iso3c country code for this entry. This is because, it is not a country name. “계” means total. It is best to check the data to see which entries did not get an iso3c code.\n\nmissing_iso3c &lt;- trade_long |&gt; \n  filter(is.na(iso3c)) |&gt; # we only need the rows that do not have iso3c country codes\n  pull(country_kr) |&gt; # pull() function is used to extract a column as a vector\n  unique() # we need each Korean country name only once to see which ones are missing rather than having it for all years.\n\nmissing_iso3c\n\n[1] \"계\"           \"국제통화기금\" \"기타\"         \"기타국\"      \n\n\nThey mean “total”, “IMF”, “other”, and “other countries” in Korean. In other words, we are not missing any countries, which is good.\nNow let’s convert the Korean country names in the aid data into iso3c country codes:\n\naid &lt;- iso3c_kr(aid, \"country_kr\") #you copy paste the column name that has the Korean country names.\n\naid[c(50, 150, 250, 350, 450, 550),c(1, 6, 2:5)] |&gt; gt::gt()\n\n\n\n\n\n\ncountry_kr\nyear\nsector\nno_of_projects\naid_usd\naid_krw\n\n\n\n베트남\n2019\n통신정책, 계획 및 행정(voluntary code)\n2\n232334\n270736486\n\n\n캄보디아\n2019\n11321\n1\n85815\n99999361\n\n\n미얀마\n2019\n사회보호/보장\n1\n103460\n120560903\n\n\n라오스\n2019\n비정규 농업훈련\n1\n107958\n125802378\n\n\n몽골\n2019\n의료서비스\n5\n511824\n596423389\n\n\n필리핀\n2019\n농업용수자원\n2\n0\n0\n\n\n\n\n\n\n\nOnce you know the iso3c country codes, you can get the English country names, or other country codes (such as Correlates of War country codes) using the countrycode package, for example.\n\ntrade_long &lt;- trade_long |&gt; \n  mutate(country_name = countrycode::countrycode(iso3c, origin = \"iso3c\", destination = \"country.name\"))\n\ntrade_long[c(50, 150, 250, 350, 450, 550),c(1, 5, 6, 2:4)] |&gt; gt::gt()\n\n\n\n\n\n\ncountry_kr\niso3c\ncountry_name\nyear\nexport_kosis\nimport_kosis\n\n\n\n계\nNA\nNA\n2014\n572664607000\n525514506000\n\n\n아랍에미리트 연합\nARE\nUnited Arab Emirates\n1996\n1377933000\n2259205000\n\n\n앤티가바부다\nATG\nAntigua & Barbuda\n1978\nNA\nNA\n\n\n앵귈라\nAIA\nAnguilla\n2019\n817000\n1000\n\n\n아르메니아\nARM\nArmenia\n2001\n1255000\n43000\n\n\n앙골라\nAGO\nAngola\n1983\n235000\nNA\n\n\n\n\n\n\n\nMore importantly, iso3c_kr function allows users to be able to join different datasets that have Korean country names. For example, one can join the trade data with the aid data using the iso3c country codes. In this example, I will join the trade data with the aid data using the iso3c country codes.\n\ntrade_aid &lt;- trade_long |&gt; \n  left_join(aid, by = c(\"iso3c\", \"year\"), suffix = c(\"_trade\", \"_aid\"))\n\ntrade_aid |&gt;\n  filter(year == 2019 & !is.na(iso3c)) |&gt; # just as a sample, we only need the data for 2019 and we exclude the rows that do not have iso3c country codes\n  slice(c(30, 130, 230, 330, 430, 530)) |&gt; # just as a sample, let's only look at the rows 30, 130, 230, 330, 430, and 530\n  select(c(iso3c, country_kr_trade, country_kr_aid, year, export_kosis, import_kosis, aid_usd)) |&gt; # just as a sample, let's only look at the columns that we are interested in\n  gt::gt()\n\n\n\n\n\n\niso3c\ncountry_kr_trade\ncountry_kr_aid\nyear\nexport_kosis\nimport_kosis\naid_usd\n\n\n\nAFG\n아프가니스탄\n아프가니스탄\n2019\n49930000\n38000\n6081\n\n\nBGD\n방글라데시\n방글라데시\n2019\n1282342000\n404703000\n746593\n\n\nBOL\n볼리비아\n볼리비아\n2019\n30434000\n450576000\n535262\n\n\nCOD\n콩고 민주공화국\n콩고민주공화국(DR콩고)\n2019\n37083000\n411274000\n0\n\n\nCHN\n중국\n중국\n2019\n136202533000\n107228736000\n0\n\n\nDOM\n도미니카 공화국\n도미니카공화국\n2019\n252420000\n88516000\n25792\n\n\n\n\n\n\n\nVoilà! Now we have a dataset that has both trade and aid data, both of which originally did not have consistent country names or country codes. If we only used country_kr column to join the two datasets, we would have failed to merge all the data, such as “콩고 민주공화국” and “콩고민주공화국(DR콩고)”, both of which are Democratic Republic of the Congo; or “도미니카 공화국” and “도미니카공화국” (Dominican Republic) which merelt have a space difference between the words. But with the iso3c_kr function, we were able to merge the two datasets successfully.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#working-with-dates",
    "href": "wrangling.html#working-with-dates",
    "title": "\n5  Data Wrangling\n",
    "section": "\n5.10 Working with dates",
    "text": "5.10 Working with dates\nTo be added",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "wrangling.html#footnotes",
    "href": "wrangling.html#footnotes",
    "title": "\n5  Data Wrangling\n",
    "section": "",
    "text": "This subsection is adapted from the vignette of the iso3c_kr function in the kdiplo package.↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "text.html",
    "href": "text.html",
    "title": "\n9  Korean Text Analysis\n",
    "section": "",
    "text": "9.1 Libraries\nFirst, we need to install bitNLP which requires us to install the MeCab library for Korean text analysis. Uncomment the following lines in your first usage. After the first usage, you can comment out the installation lines.\n# install.packages(\"remotes\")\n# remotes::install_github(\"bit2r/bitNLP\")\nlibrary(bitNLP)\n# install_mecab_ko()\n# install.packages(\"RcppMeCab\")\nNow let’s load the necessary libraries. If you are missing any of the following packages, you can install them by uncommenting the install.packages lines.\n# install.packages(\"tidyverse\")\n# install.packages(\"pdftools\")\n# install.packages(\"rvest\")\n# install.packages(\"tidytext\")\n# install.packages(\"igraph\")\n# install.packages(\"ggraph\")\n# install.packages(\"extrafont\")\n# install.packages(\"devtools\")\n# devtools::install_github(\"koheiw/stopwords\")\nlibrary(tidyverse)\nlibrary(pdftools)\nlibrary(rvest)\nlibrary(tidytext)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(extrafont)\nlibrary(stopwords)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#loading-pdf-data",
    "href": "text.html#loading-pdf-data",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.2 Loading pdf Data",
    "text": "9.2 Loading pdf Data\nLet’s analyze the text from Korea’s 2024 Public Diplomacy Comprehensive Implementation Plan (2024년 공공외교 종합시행계획 개요) which is available as a pdf file on the Ministry of Foreign Affairs’ (MOFA) website1.\nIf the pdf file is in your local directory, you can load it using the following code.\n\n# Load PDF\npdf_path &lt;- \"data/2024공공외교.pdf\"\n\nAlternatively, you can download the pdf file from the MOFA’s website using the download.file function. You can then load the pdf file using the pdf_path variable. Working with the online pdf file and the local pdf file is the same. We can do either. For now, I will use the local pdf file since the MOFA might change the url for the pdf later. That is why I commented the download code. You can comment the earlier code for the local pdf file and uncomment the following code for the online pdf file.\n\n# Download PDF\n#file &lt;- tempfile()\n\n# This url works for now. But MOFA might change it later. You can replace the link with any other link you want to download.\n\n#url &lt;- \"https://www.mofa.go.kr/cntntsDown.do?path=www&physic=2024%EB%85%84%EB%8F%84_%EA%B3%B5%EA%B3%B5%EC%99%B8%EA%B5%90_%EC%A2%85%ED%95%A9%EC%8B%9C%ED%96%89%EA%B3%84%ED%9A%8D.pdf&real=2024%EB%85%84%EB%8F%84_%EA%B3%B5%EA%B3%B5%EC%99%B8%EA%B5%90_%EC%A2%85%ED%95%A9%EC%8B%9C%ED%96%89%EA%B3%84%ED%9A%8D.pdf\"\n\n# download.file(url, pdf_path, headers = c(\"User-Agent\" = \"My Custom User Agent\"))\n\nNow let’s extract the text from the pdf file using the pdf_text function from the pdftools package.\n\n# Extract text\npdf_text_all &lt;- pdf_text(pdf_path)\n\nNow, pdf_text_all is a list of character vectors, where each element corresponds to a page in the pdf file. For example, we can look at the 4th page of the pdf file in the following way.\n\n# Let's look at the 4th page\npdf_text_all[4]\n\n[1] \"참고       기관별 사업규모 및 예산\\n[중앙행정기관]\\n                  ‘24년     ‘23년      ‘24년 예산         ‘23년 예산\\n       기관명\\n                  사업수      사업수         (백만원)           (백만원)\\n 1    교육부             16       16          194,996          94,963\\n 2    과학기술정보통신부        6        6           32,852          40,283\\n 3    외교부             73       63           40,215          39,419\\n3-1   한국국제교류재단        37       41           42,514          44,664\\n 4    통일부              6        6            1,831           2,386\\n 5    법무부              3        3           15,068          14,346\\n 6    국방부              7        8            6,165           7,221\\n 7    행정안전부            3        3              594             574\\n 8    문화체육관광부         21       22          185,478         145,049\\n 9    농림축산식품부          6        7            3,048           4,268\\n10    보건복지부            7        7            6,497           8,557\\n11    환경부              1        1            1,888           1,427\\n12    고용노동부            1        1            1,264           1,529\\n13    여성가족부            6        7            1,531           2,748\\n14    국토교통부            4        4            2,394           2,394\\n15    중소벤처기업부          5        5            7,246           5,548\\n16    국가보훈부            1        1            8,774           3,637\\n17    법제처              2        2              327             327\\n18    해양수산부            1        1              100             100\\n19    재외동포청            5        -           22,289               -\\n        합계           211      204         475,038         419,440\\n\\n[지자체]\\n                  ‘24년     ‘23년      ‘24년 예산         ‘23년 예산\\n       기관명\\n                  사업수      사업수         (백만원)           (백만원)\\n 1    경기도             25       14          21,558            3,899\\n 2    강원특별자치도         10       11          78,593          11,024\\n 3    충청북도             7        8             789              736\\n 4    충청남도            10       10           2,508            1,731\\n 5    전라북도            19       19           2,626          10,703\\n 6    전라남도            13       13           2,962            6,917\\n 7    경상북도            18       18            2709            3,314\\n 8    경상남도             8       10            미정              1,408\\n 9    제주특별자치도         23       24           4,433            7,343\\n10    서울특별시           31       31          10,005            9,628\\n11    부산광역시           36       35           3,017            2,355\\n12    대구광역시           11       11             316              321\\n13    인천광역시           26       25           5,516            5,008\\n14    광주광역시           22       26           3,487            6,459\\n15    대전광역시           38       44            3685            3,848\\n16    울산광역시           17       14           1,302              660\\n17    세종특별자치시          8        9              96              373\\n        합계           322      322         143,602          75,727\\n\\n\\n                             - 4 -\\n\"\n\n\nYou can see that there are \\n characters, which refers to newline (new line) in the text. Let’s split the text by the newline character and look at the first 10 lines of the 4th page. We can split the text into lines by using the str_split function from the stringr package, which is part of tidyverse. So, we do not need to load it separately. Let’s look at the first six lines of the 4th page.\n\n# Look at the first 10 lines of the 4th page\npdf_text_all[4] |&gt; \n  # Split by newline character.\n  str_split(\"\\n\") |&gt; \n  # Unlist\n  unlist() |&gt;\n  # Take the first 10 lines\n  head(10)\n\n [1] \"참고       기관별 사업규모 및 예산\"                                         \n [2] \"[중앙행정기관]\"                                                             \n [3] \"                  ‘24년     ‘23년      ‘24년 예산         ‘23년 예산\"       \n [4] \"       기관명\"                                                              \n [5] \"                  사업수      사업수         (백만원)           (백만원)\"   \n [6] \" 1    교육부             16       16          194,996          94,963\"      \n [7] \" 2    과학기술정보통신부        6        6           32,852          40,283\"\n [8] \" 3    외교부             73       63           40,215          39,419\"      \n [9] \"3-1   한국국제교류재단        37       41           42,514          44,664\" \n[10] \" 4    통일부              6        6            1,831           2,386\"      \n\n\nThe 4th page in the pdf file looks like this:\n\n\n2024 Public Diplomacy Comprehensive Implementation Plan, p. 4",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#pdf-table-extraction",
    "href": "text.html#pdf-table-extraction",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.3 pdf Table Extraction",
    "text": "9.3 pdf Table Extraction\nLet’s try to extract the second table on page 4 of the pdf file. The table has the number of public diplomacy projects and budgets for first-tier local administration unit (hereafter, province_city for short) in Korea. We will unlist each line as we did earlier so that we can see the table in a more readable way.\n\n# Look at the first 10 lines of the 4th page\nlines_pdf_4 &lt;- pdf_text_all[4] |&gt; \n  # Split by newline character.\n  str_split(\"\\n\") |&gt; \n  # Unlist\n  unlist()\n\nFirst, let’s look at the 29th and 30th lines for the column names in the pdf file.\n\nlines_pdf_4[29:30]\n\n[1] \"                  ‘24년     ‘23년      ‘24년 예산         ‘23년 예산\"\n[2] \"       기관명\"                                                       \n\n\nThe column names are the line number, province or city’s name, project numbers for 2024 and 2023 respectively, and the budget for 2024 and 2023 in million Korean Won respectively. Let’s use the following English column names that correspond to the Korean column names in the pdf file.\n\n# Column names\ncol_names &lt;- c(\"no\", \"province_city\", \"project_no_2024\", \"project_no_2023\", \"budget_2024\", \"budget_2023\")\n\nBy observing the lines_pdf_4 object using view(lines_pdf_4), we can see that the second table starts from the 32nd line and ends on the 48th. We will extract only those lines. We will use str_trim “removes whitespace from start and end of string”. We will also use str_replace_all to remove commas from each line to convert entries into numbers. We will then split each line based on two or more consecutive spaces (our string is “\\s{2,}”) using str_split and simplify the result into a matrix. We will convert this matrix into a data frame with non-factor columns using data.frame(stringsAsFactors = FALSE). We will set the column names of the data frame using the col_names vector that we created above. These explanations are also available in each step in the following code chunk.\n\n# Select lines 32 to 48 from the lines_pdf_4 data frame\nprovince_city_pd &lt;- lines_pdf_4[32:48] |&gt;\n  # Trim whitespace from both ends of each element in the selected rows\n  str_trim() |&gt;\n  # Replace all commas with an empty string in each element\n  str_replace_all(\",\", \"\") |&gt;\n  # Split each element based on 2 or more consecutive spaces and simplify into a matrix\n  str_split(\"\\\\s{2,}\", simplify = TRUE) |&gt;\n  # Convert the matrix into a data frame with non-factor columns\n  data.frame(stringsAsFactors = FALSE) |&gt;\n  # Set column names for the data frame using the provided 'col_names' vector\n  setNames(col_names)\n\nLet’s rearrange the table (which is originally in alphabetical order) by descending order based on public diplomacy budgets in 2024.\n\nprovince_city_pd |&gt;\n  arrange(desc(budget_2024))\n\n   no  province_city project_no_2024 project_no_2023 budget_2024 budget_2023\n1   8       경상남도               8              10        미정        1408\n2  17 세종특별자치시               8               9          96         373\n3   3       충청북도               7               8         789         736\n4   2 강원특별자치도              10              11       78593       11024\n5  13     인천광역시              26              25        5516        5008\n6   9 제주특별자치도              23              24        4433        7343\n7  15     대전광역시              38              44        3685        3848\n8  14     광주광역시              22              26        3487        6459\n9  12     대구광역시              11              11         316         321\n10 11     부산광역시              36              35        3017        2355\n11  6       전라남도              13              13        2962        6917\n12  7       경상북도              18              18        2709        3314\n13  5       전라북도              19              19        2626       10703\n14  4       충청남도              10              10        2508        1731\n15  1         경기도              25              14       21558        3899\n16 16     울산광역시              17              14        1302         660\n17 10     서울특별시              31              31       10005        9628\n\n\nBut these province_city names are in Korean since the document was in Korean. Let’s practice extracting a table from internet then to find English names for these Korean provinces or cities. As of May 6, 2024, Wikipedia’s list of South Korea’s administrative divisions seems to be correct. Let’s extract the table there.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#html-table-extraction",
    "href": "text.html#html-table-extraction",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.4 html Table Extraction",
    "text": "9.4 html Table Extraction\nWe will use the rvest package to extract the table from the Wikipedia page. We will use the read_html function to read the html content of the Wikipedia page. We will then use the html_node function to select the table we want to extract. You can refer to rvest package for more information on how to extract what you want. We can use the xpath of the table we want to extract. You can find the xpath of the table by right-clicking on the table on the Wikipedia page and selecting “Inspect” or “Inspect Element” depending on your browser. You can then right-click on the highlighted html element in the “Elements” tab of the “Developer Tools” and select “Copy” -&gt; “Copy XPath”. The xpath of the table we want to extract is //*[@id=\"mw-content-text\"]/div[1]/table[5]. We will use the html_table function to extract the table as a data frame. We will use the fill = TRUE argument to fill in the missing values in the table.\n\nhtml &lt;- read_html(\"https://en.wikipedia.org/wiki/Administrative_divisions_of_South_Korea\")\n\ntable &lt;- html |&gt; \n  html_node(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[5]') |&gt;\n  html_table(fill = TRUE)\n\nLet’s look at the first 10 rows of the table.\n\nhead(table)\n\n# A tibble: 6 × 9\n  Code  Emblem Name   Official English nam…¹ Hangul Hanja Population 2020 Cens…²\n  &lt;chr&gt; &lt;lgl&gt;  &lt;chr&gt;  &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;                 \n1 KR-11 NA     Seoul… Seoul                  서울…  .mw-… 9,586,195             \n2 KR-26 NA     Busan… Busan                  부산…  釜山… 3,349,016             \n3 KR-27 NA     Daegu… Daegu                  대구…  大邱… 2,410,700             \n4 KR-28 NA     Inche… Incheon                인천…  仁川… 2,945,454             \n5 KR-29 NA     Gwang… Gwangju                광주…  光州… 1,477,573             \n6 KR-30 NA     Daeje… Daejeon                대전…  大田… 1,488,435             \n# ℹ abbreviated names: ¹​`Official English name[5]`, ²​`Population 2020 Census`\n# ℹ 2 more variables: `Area (km2)` &lt;chr&gt;,\n#   `Population density  2022 (per km2)` &lt;chr&gt;\n\n\nPerfect! Now, let’s keep only the columns that we will need.\n\n# Select columns 4 and 5 from the table\ntable &lt;- table |&gt;\n  select(4:5)\n\n# Let's change the English province_city column name.\n\ntable &lt;- table |&gt;\n  rename(province_city_eng = `Official English name[5]`)\n\nLet’s hope that the Korean names in the Wikipedia table and the MOFA’s pdf file are the same. Let’s merge the two tables based on the Korean names.\n\n# Merge the two tables based on the Korean names\nprovince_city_pd_joined &lt;- province_city_pd |&gt;\n  left_join(table, by = c(\"province_city\" = \"Hangul\"))\n\nLet’s see if we have any missing values in the English names.\n\n# Check for missing values in the English names\nprovince_city_pd_joined |&gt;\n  filter(is.na(province_city_eng))\n\n  no province_city project_no_2024 project_no_2023 budget_2024 budget_2023\n1  5      전라북도              19              19        2626       10703\n  province_city_eng\n1              &lt;NA&gt;\n\n\nWe almost got it! The only difference is 전라북도 (North Jeolla Province) in the MOFA’s pdf file which is written as 전북특별자치도 (Jeonbuk State) in the Wikipedia table. Let’s fix this.\n\n# Move the English name column next to the Korean name column, and remove the 'no' column\n\nprovince_city_pd_joined &lt;- province_city_pd_joined |&gt;\n  select(province_city, province_city_eng, everything(), -no)\n\n# Fix the English name of 전라북도\n\nprovince_city_pd_joined &lt;- province_city_pd_joined |&gt;\n  mutate(province_city_eng = ifelse(province_city == \"전라북도\", \"North Jeolla province_city\", province_city_eng))",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#text-analysis",
    "href": "text.html#text-analysis",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.5 Text Analysis",
    "text": "9.5 Text Analysis\n\n9.5.1 Word Frequency\nThis time let’s look at all of the text in the 2024 Public Diplomacy Comprehensive Implementation Plan. We will combine all the text into a single character vector.\n\n# Combine text\npdf_text &lt;- str_c(pdf_text_all, collapse = \" \")\n\nWe will now split the text into words using the str_split function from the stringr package. We will then convert the result into a data frame with non-factor columns using the data.frame(stringsAsFactors = FALSE) function. We will set the column name of the data frame as word.\n\n# Split the text into words\nwords &lt;- pdf_text |&gt;\n  # Split the text into words\n  str_split(\"\\\\s+\") |&gt;\n  # Convert the result into a data frame with non-factor columns\n  data.frame(stringsAsFactors = FALSE) |&gt;\n  # Set the column name of the data frame as \"word\"\n  setNames(\"word\")\n\nLet’s look at the first 10 rows of the data frame.\n\nhead(words, 10)\n\n           word\n1              \n2        2024년\n3      공공외교\n4  종합시행계획\n5          개요\n6             \n7          수립\n8          근거\n9             ❑\n10   공공외교법\n\n\nNow, let’s count the frequency of each word in the text using the count function from the dplyr package package. We will then arrange the result in descending order based on the frequency of the words.\n\n# Count the frequency of each word\nword_freq &lt;- words |&gt;\n  count(word, sort = TRUE)\n\nLet’s look at the first 10 rows of the data frame\n\nhead(word_freq, 10)\n\n       word  n\n1        및 72\n2         - 55\n3  공공외교 40\n4        등 33\n5        ㅇ 28\n6     개최, 22\n7      통한 22\n8      사업 18\n9      제고 18\n10     강화 17\n\n\nThis is not very useful. There are two main issues with Korean text. First, Korean text does not have consistent spacing between words. Second, Korean text has particles and other morphemes that are not words. We will address these issues now.\n\n9.5.2 Spacing in Korean Text\nLet’s get the spacing right in Korean text using the bitNLP package’s get_spacing function, which will add spaces between words in the Korean text. So, for example “한국공공외교” will become “한국 공공 외교”.\n\n# Get the spacing right in Korean text\npdf_text_ko &lt;- get_spacing(pdf_text)\n\nNow, let’s split the text into words again using the str_split function from the stringr package.\n\n# Split the text into words\nwords_ko &lt;- pdf_text_ko |&gt;\n  # Split the text into words\n  str_split(\"\\\\s+\") |&gt;\n  # Convert the result into a data frame with non-factor columns\n  data.frame(stringsAsFactors = FALSE) |&gt;\n  # Set the column name of the data frame as \"word\"\n  setNames(\"word\")\n\nLet’s analyze the word frequency in the text again.\n\n# Count the frequency of each word\nword_freq_ko &lt;- words_ko |&gt;\n  count(word, sort = TRUE)\n\nhead(word_freq_ko, 10)\n\n   word   n\n1     ▴ 175\n2     (  97\n3     -  80\n4    및  73\n5  외교  67\n6  공공  62\n7  국제  36\n8  사업  35\n9    등  33\n10 해외  30\n\n\nWe have many special characters in the text. Let’s remove all characters except for Korean characters, spaces, English letters, and numbers using the str_replace_all function from the stringr package.\n\n# Remove all characters except for Korean characters, spaces, English letters, and numbers\nword_freq_ko &lt;- pdf_text_ko |&gt;\n  # Remove all characters except Korean characters, English letters, numbers, and spaces\n  str_replace_all(\"[^가-힣a-zA-Z0-9\\\\s]\", \"\") |&gt;\n  # Split the cleaned text into words based on one or more spaces\n  str_split(\"\\\\s+\") |&gt;\n  # Convert the list result into a data frame with non-factor columns\n  data.frame(stringsAsFactors = FALSE) |&gt;\n  # Set the column name of the data frame as \"word\"\n  setNames(\"word\")\n\nLet’s analyze the word frequency in the text again.\n\n# Count the frequency of each word\nword_freq_ko &lt;- word_freq_ko |&gt;\n  count(word, sort = TRUE)\n\nhead(word_freq_ko, 10)\n\n   word  n\n1    및 73\n2  외교 67\n3  공공 62\n4  개최 44\n5  사업 37\n6  국제 36\n7    등 35\n8  해외 30\n9  문화 29\n10 추진 28\n\n\nThis is much better! We have removed the special characters and have more meaningful words in the text.\nWe can also remove some common stopwords in Korean using the stopwords function in stopwords package along with the stopwords-iso library that has Korean stopwords.\n\nstopwords &lt;- stopwords(\"ko\", source = \"stopwords-iso\") |&gt;\n  as.data.frame() |&gt;\n  setNames(\"word\")\n\n# Remove stopwords\n\nword_freq_ko &lt;- word_freq_ko |&gt;\n  # anti_join (remove) stopwords\n  anti_join(stopwords, by = \"word\")\n\nLet’s count the frequency of each word in the text again.\n\nhead(word_freq_ko, 10)\n\n   word  n\n1  외교 67\n2  공공 62\n3  개최 44\n4  사업 37\n5  국제 36\n6  해외 30\n7  문화 29\n8  추진 28\n9  운영 25\n10 강화 24\n\n\nThis way, we removed words such as 및 (and) and 등 (etc.) from the text.\nLet’s move on to morpheme analysis which makes more sense in Korean text analysis context.\n\n9.5.3 Morpheme Analysis in Korean Text\nLet’s analyze the morphemes in the Korean text using the morpho_mecab function from the bitNLP package, which will extract morphemes from the Korean text.\n\n# Analyze the morphemes in the Korean text\nmorphemes &lt;- morpho_mecab(pdf_text_ko)\n\nThis creates a list of character vectors, where each element corresponds to a morpheme in the text. We can also combine all of the morphemes and tokenize them into a single character vector.\n\n# Combine all the morphemes into a single character vector\n\nmorphemes_single &lt;- morpho_mecab(pdf_text_ko, indiv = FALSE)\n\nNow, let’s split the text into words again this time by converting morphemes_single into a data frame using the as.data.frame function. We will set the column name of the data frame as “word”.\n\n# Split the text into words\nwords_morphemes &lt;- morphemes_single |&gt;\n  as.data.frame() |&gt;\n  # Set the column name of the data frame as \"word\"\n  setNames(\"word\")\n\nWe will now count the frequency of each morpheme in the text using the count function from the dplyr package package. We will then arrange the result in descending order based on the frequency of the morphemes.\n\n# Count the frequency of each morpheme\n\nmorpheme_freq &lt;- words_morphemes |&gt;\n  count(word, sort = TRUE)\n\nhead(morpheme_freq, 10)\n\n   word  n\n1  외교 68\n2  공공 62\n3  개최 46\n4  국제 39\n5  사업 37\n6  해외 30\n7  문화 29\n8  추진 28\n9  운영 26\n10 계획 25\n\n\nNow, this is more like it!\nLet’s visualize the frequency of the morphemes in the text using a bar plot. Before that let’s address the font issue with Korean text in the plot.\nKorean text sometimes is not visible in the graph due to the font issue. This was the case in my Macbook. Let’s set the font to one that supports Korean characters. We will use the extrafont package to set the font to one that supports Korean characters. We will use the font_import function to import the fonts from the system. This may take some time. You only need to do it once. That’s why I commented it. You can uncomment it in first usage.\n\n# Load extrafont and register fonts\n\n#font_import()  # This might take a while if it's the first time you're running it\n\nWe will then use the loadfonts function to load the fonts. We will use the fonts function to display the available fonts and find one that supports Korean characters. We will set the font to one that supports Korean characters. For now, I have chosen “Arial Unicode MS” as the Korean font. You can replace it with a font from your system that supports Korean characters if necessary.\n\n#loadfonts(device = \"all\")\n\n# Display available fonts, find one that supports Korean\n#fonts()\n\n# Set the font to one that supports Korean characters\nkorean_font &lt;- \"Arial Unicode MS\"  # Replace with a font from your system that supports Korean if necessary\n\nWe will use the ggplot function from the ggplot2 package to create the plot. We will use the geom_col function to add the bars to the plot. We will use the theme_minimal function to set the theme of the plot to minimal. We will use the theme function to adjust the font size in the plot. We will set the font size to 10. We will use the labs function to add the title and labels to the plot. We will visualize only the most frequent 20 morphemes in the text.\n\n# Visualize the frequency of the morphemes in the text\n\nmorpheme_freq |&gt; \n  top_n(20) |&gt; \n  mutate(word = reorder(word, n)) |&gt; ggplot(aes(word, n)) + \n  geom_col(fill = \"#2196f3\") +\n  coord_flip() +\n  theme_minimal() +\n  # use Korean font\n  theme(text = element_text(family = korean_font, size = 10)) +\n  labs(title = \"Frequency of Morphemes in Korean Text\", x = \"Morpheme\", y = \"Frequency\")\n\n\n\n\n\n\n\n\n9.5.4 Word Network in Korean Text\nLet’s analyze the word network in the Korean text using the tokenize_noun_ngrams function from the bitNLP package which builds on tidytext package. We will use the tokenize_noun_grams function to extract the noun word network from the Korean text.\n\n# We can use a user-defined dictionary to improve the accuracy of the tokenization. We will rely on the one provided by the `bitNLP` package.\n\ndic_path &lt;- system.file(\"dic\", package = \"bitNLP\")\ndic_file &lt;- glue::glue(\"{dic_path}/buzz_dic.dic\")\n\nword_network &lt;- tokenize_noun_ngrams(pdf_text_ko, simplify = TRUE, user_dic = dic_file, n = 2) |&gt;\n  as.data.frame() |&gt;\n  setNames(\"paired_words\")\n\nNow, let’s separate the paired words into two columns using the separate function from the tidyr package which is loaded as part of the tidyverse package. This will allow us to create bigrams from the paired words.\n\nword_network_separated &lt;- word_network |&gt;\n  separate(paired_words, c(\"word1\", \"word2\"), sep = \" \")\n\nWe will now count the frequency of each bigram in the text using the count function from the dplyr package package, which is also party of the tidyverse. We will then arrange the result in descending order based on the frequency of the bigrams.\n\n# new bigram counts:\nword_network_counts &lt;- word_network_separated |&gt;\n  count(word1, word2, sort = TRUE)\n\nWe will now create a graph from the bigram counts using the graph_from_data_frame function from the igraph package. We will use the ggraph function from the ggraph package to create the graph. We will use the geom_edge_link function to add the edges to the graph. We will use the geom_node_point function to add the nodes to the graph. We will use the geom_node_text function to add the labels to the nodes in the graph. We will set the font to the Korean font that we set earlier. We will then adjust the font in the graph. Here, n &gt;= 6 is used to filter out bigrams that appear less than 6 times. You can adjust this number as needed. You can check out ggraph layout options here.\n\nword_network_select &lt;- word_network_counts |&gt;\n  filter(n &gt;= 6) |&gt;\n  graph_from_data_frame() |&gt;\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(color = \"#2196f3\", size = 4) +\n  geom_node_text(aes(label = name), family = korean_font, vjust = 2, size = 4) +  # Set family to Korean font\n  theme_void()\n\n\nword_network_select\n\n\n\n\n\n\n\n\n9.5.5 Sentiment Analysis\n\n9.5.6 Topic Modeling",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#korean-tweet-analysis",
    "href": "text.html#korean-tweet-analysis",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.6 Korean Tweet Analysis",
    "text": "9.6 Korean Tweet Analysis",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#further-readings",
    "href": "text.html#further-readings",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.7 Further Readings",
    "text": "9.7 Further Readings",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#references",
    "href": "text.html#references",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.8 References",
    "text": "9.8 References",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#session-info",
    "href": "text.html#session-info",
    "title": "\n9  Korean Text Analysis\n",
    "section": "\n9.9 Session Info",
    "text": "9.9 Session Info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Seoul\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] stopwords_2.3     extrafont_0.19    ggraph_2.2.1      igraph_2.0.3     \n [5] tidytext_0.4.2    rvest_1.0.4       pdftools_3.4.0    lubridate_1.9.3  \n [9] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n[13] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n[17] tidyverse_2.0.0   bitNLP_1.4.3.9000\n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1    viridisLite_0.4.2   farver_2.1.1       \n [4] viridis_0.6.5       fastmap_1.1.1       tweenr_2.0.3       \n [7] janeaustenr_1.0.0   promises_1.3.0      shinyjs_2.1.0      \n[10] digest_0.6.35       timechange_0.3.0    mime_0.12          \n[13] lifecycle_1.0.4     qpdf_1.3.3          tokenizers_0.3.0   \n[16] magrittr_2.0.3      compiler_4.4.0      rlang_1.1.3        \n[19] sass_0.4.9          tools_4.4.0         utf8_1.2.4         \n[22] knitr_1.46          labeling_0.4.3      askpass_1.2.0      \n[25] graphlayouts_1.1.1  htmlwidgets_1.6.4   curl_5.2.1         \n[28] xml2_1.3.6          miniUI_0.1.1.1      ngram_3.2.3        \n[31] withr_3.0.0         grid_4.4.0          polyclip_1.10-6    \n[34] fansi_1.0.6         xtable_1.8-4        colorspace_2.1-0   \n[37] extrafontdb_1.0     scales_1.3.0        MASS_7.3-60.2      \n[40] cli_3.6.2           rmarkdown_2.26      generics_0.1.3     \n[43] RcppParallel_5.1.7  rstudioapi_0.16.0   httr_1.4.7         \n[46] tzdb_0.4.0          cachem_1.0.8        ggforce_0.4.2      \n[49] RcppMeCab_0.0.1.2   parallel_4.4.0      rhandsontable_0.3.8\n[52] vctrs_0.6.5         Matrix_1.7-0        jsonlite_1.8.8     \n[55] hms_1.1.3           ggrepel_0.9.5       jquerylib_0.1.4    \n[58] shinyBS_0.61.1      glue_1.7.0          stringi_1.8.3      \n[61] gtable_0.3.5        later_1.3.2         munsell_0.5.1      \n[64] pillar_1.9.0        htmltools_0.5.8.1   R6_2.5.1           \n[67] tidygraph_1.3.1     evaluate_0.23       shiny_1.8.1.1      \n[70] lattice_0.22-6      SnowballC_0.7.1     memoise_2.0.1      \n[73] DataEditR_0.1.5     httpuv_1.6.15       bslib_0.7.0        \n[76] Rcpp_1.0.12         Rttf2pt1_1.3.12     gridExtra_2.3      \n[79] xfun_0.43           pkgconfig_2.0.3",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "text.html#footnotes",
    "href": "text.html#footnotes",
    "title": "\n9  Korean Text Analysis\n",
    "section": "",
    "text": "Please bear in mind that MOFA website’s url might change later, making this hyperlink broken. In that case, you can download the pdf file on the MOFA’s website by searching for “2024년 공공외교 종합시행계획 개요”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korean Text Analysis</span>"
    ]
  },
  {
    "objectID": "productivity.html",
    "href": "productivity.html",
    "title": "12  Productivity Tools",
    "section": "",
    "text": "Setting up Github.\nCreating a new Github project.\nCopilot etc.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Productivity Tools</span>"
    ]
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "13  Working with API to get Korean Data",
    "section": "",
    "text": "WDI etc. readily available packages\nCreating your own API\nhttps://httr2.r-lib.org/articles/wrapping-apis.html\nhttps://www.andrewheiss.com/blog/2024/01/12/diy-api-plumber-quarto-ojs/_book/",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Working with API to get Korean Data</span>"
    ]
  },
  {
    "objectID": "kdiplo.html",
    "href": "kdiplo.html",
    "title": "14  Making Korean Data Visualization Social",
    "section": "",
    "text": "14.1 #kdiplo #kdiploviz\nI love Korea, and I love data.\nCombining my enthusiasm for Korean Studies and data, I am initiating an exciting project to make engaging and valuable Korean datasets publicly accessible… in an enjoyable manner!\nI invite you to explore and interact with the data I will be sharing. Let’s craft stories together using these datasets and connect through the hashtags #kdiplo, #kdiploviz, #kdata, and #kdataviz.\nRecently, I have created several novel datasets on Korean diplomacy for my research1, mainly focusing on high-level diplomatic visits (both outgoing and incoming), their formats (bilateral, multilateral, informal), nature (such as state visits), purposes (economic, security, etc.), timelines, and the conveners in multilateral contexts among others.\nI will make these datasets available via a new R package, #kdiplo. Although this is a work in progress, the first version is already shaping up.\nThe current development version features a pivotal function (along with an accompanying dataset) designed to assist researchers in merging various Korean datasets by country names. Due to inconsistent naming conventions across Korean government datasets (for instance, Thailand might appear as 태국 [Taeguk] or 타이 [Tai]), the kdiplo::iso3c function creates iso3c country codes for Korean country names, simplifying the joining process (similar to countrycode::countrycode).\nNext on the agenda is adding comprehensive Korean trade data spanning from 1948 to 2023, inclusive of multiple sources and estimations/ imputations for missing data.\nMore datasets are on the way, and I am open to data requests.\nStay tuned (follow hashtags #kdiplo, #kdiploviz #kdata, and #kdataviz) for more updates on (https://github.com/kjayhan/kdiplo) - a one-stop public repository for data insights on Korean diplomacy and foreign policy!\nFor now check this website out, which I will soon update as well.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Making Korean Data Visualization Social</span>"
    ]
  },
  {
    "objectID": "kdiplo.html#kdata-kdataviz",
    "href": "kdiplo.html#kdata-kdataviz",
    "title": "14  Making Korean Data Visualization Social",
    "section": "14.2 #kdata #kdataviz",
    "text": "14.2 #kdata #kdataviz\nWhile my main interests in Korean Studies lie in foreign policy and (public) diplomacy, I am also interested in everything related to Korea, from business to education to culture.\nIndeed, I was trained as an economist, with a double major in international trade, wrote my master’s thesis on Korean popular culture (from an international relations angle), and have published at least 8 peer-reviewed articles on international student mobility programs (from a public diplomacy angle).\nSo… in addition to the #kdiplo package, I am happy to announce that, I am also building another package, #kdata, dedicated to datasets on Korean business, culture, and education. Although this is a work-in-progress, I have already uploaded multiple datasets to the #kdiplo repository. I will upload documentation and vignettes for these datasets soon.\nTo kick things off with the vibrant Spring season in Korea, I present our first challenge: the Korean Festivals dataset! 🌸🎎🎇\nExplore and interact with the data available at #kdiplo kdiplo::korean_festivals_data.\nCheck out my blog post where I’ve used this dataset.\nI encourage you to dive into this dataset and share your insights. Remember to use hashtags #kdiplo, #kdiploviz #kdata, and #kdataviz in your posts across various social media platforms!",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Making Korean Data Visualization Social</span>"
    ]
  },
  {
    "objectID": "kdiplo.html#footnotes",
    "href": "kdiplo.html#footnotes",
    "title": "14  Making Korean Data Visualization Social",
    "section": "",
    "text": "See these blog posts for now.↩︎",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Making Korean Data Visualization Social</span>"
    ]
  },
  {
    "objectID": "bootcamp.html",
    "href": "bootcamp.html",
    "title": "15  R for Korean Studies Bootcamps",
    "section": "",
    "text": "I plan to organize bootcamps to help Korean Studies scholars and students to jumpstart their R learning with Korean Studies-based examples.\nYou can sign up for my newsletter to get updates on the workshops.\nYou can find more information about the bootcamps here.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>R for Korean Studies Bootcamps</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ayhan, Kadir Jun. 2024. R for Korean Studies: A Gentle\nIntroduction to Computational Social Science. Draft\nVersion 0.0.1. https://r4ks.com.",
    "crumbs": [
      "References"
    ]
  }
]